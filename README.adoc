== 简介

Sek - 一个类似 Nutch 的, 基于 Hadoop 的并行式爬虫框架.

*当前尚处于构思阶段.*

构思如下:

* 日志功能.
* 参数的可配置.
* 设置种子 URL 时可以进行必要的配置, 如评分, 定义抓取间隔等.
* 基于 正则表达式 的 URL 过滤.
* URL 规范化.
* 广度优先的抓取策略.
* 插件机制. 程序只提供一个必要的骨架, 可以通过插件的机制来定制软件的运行.
* Solr 集成, 提供全文检索.(待定)
* 支持图片的抓取.(待定)

[NOTE]
====
这里对插件机制做个简单的说明. 即程序提供接口, 然后编写实现该接口的插件程序,
打包成 jar 文件放在 CLASSPATH 下, 通过配置文件的配置, 即可运行插件程序中的代码.
这样易于应用的拓展.

目前打算将 文本解析 部分以插件的机制实现. 这样就能实现特定站点运行特定的文本解析程序,
初步达到 定向抓取, 使数据更具征对性.
====

== 架构

* JDK 1.7
* Hadoop 2.5
* HDFS 做数据存储.

拟用到的类库有

* args4j
* jsoup
* log4j2
* junit

具体模块

* 种子 URL 解析, 生成种子数据库.
* 解析种子数据库, 生成此次的 fetchlist.
* 并发地获取 fetchlist 中的 URL.
* 对获取到的数据进行解析处理.
* 更新种子数据库等.
* Solr 索引, 提供全文检索(待定).

